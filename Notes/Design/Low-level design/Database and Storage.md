# Database and Storage

In low-level design, storage and database design is a critical part. It entails deciding how data will be stored and accessed efficiently. Here are some core concepts:

1. **SQL vs NoSQL**: SQL databases are traditional, structured relational databases that use structured query language (SQL) for defining and manipulating the data. On the other hand, NoSQL databases are non-relational and can store and process a wide variety of data models, including key-value, document, columnar, and graph formats. 

2. **Normalization**: In relational database design, normalization is the process of structuring a relational database in accordance with a series of so-called normal forms to reduce data redundancy and improve data integrity.

3. **Indexes**: An index is a data structure that improves the speed of data retrieval operations on a database table. It provides faster access to data rows by creating pointers to where data is stored within a database.

4. **Transactions**: A transaction is a single logical unit of work that accesses and possibly modifies the contents of a database. Transactions access data using read and write operations.

5. **Sharding**: Sharding is a type of database partitioning that separates very large databases into smaller, faster, more easily managed parts called data shards.

6. **Replication**: Replication is the process of sharing information so as to ensure consistency between redundant resources, such as software or hardware components, to improve reliability, fault-tolerance, or accessibility.

7. **Caching**: A cache is a hardware or software component that stores data so that future requests for that data can be served faster.

8. **Object-relational Mapping (ORM)**: ORM is a programming technique for converting data between incompatible type systems using object-oriented programming languages.

In terms of Python, there are many libraries that can be used to interact with databases. For SQL databases, `sqlite3` (included in the standard library) or SQLAlchemy can be used. SQLAlchemy also provides ORM capabilities. For NoSQL databases, depending on the type of NoSQL database, PyMongo (for MongoDB), redis-py (for Redis), and Apache Cassandra Python Driver (for Cassandra) are some examples.

When designing databases for your applications, consider how data will be accessed. Will there be more reads than writes? What kind of queries will be executed? This will help in deciding whether to use SQL or NoSQL, how to structure your data, whether to use indexing, etc.

Moreover, consider how your application's performance can be improved by caching frequently accessed but rarely modified data. Also, think about whether your application requires the ACID properties (Atomicity, Consistency, Isolation, Durability) provided by transactions.

Finally, for large applications that handle a lot of data, consider whether sharding or replication would be beneficial. These techniques can improve performance and ensure that your application is reliable and always available to users.

Let's go through these concepts one by one:

## **SQL vs NoSQL**:

**SQL**: SQL stands for Structured Query Language. SQL databases are relational, meaning they organize data into one or more tables. Each table identifies data with a unique key and tables can relate to each other using keys. Examples of SQL databases are MySQL, Oracle Database, PostgreSQL, and SQL Server.

**NoSQL**: NoSQL databases are non-relational, meaning they can handle structured, semi-structured, and unstructured data. They do not require a fixed schema and scale horizontally. Examples include MongoDB (document store), Apache Cassandra (wide-column store), Google Cloud Datastore (wide-column & document store), and Redis (key-value store).

SQL and NoSQL are two different paradigms for storing and retrieving data. They each have their strengths and weaknesses, and they are often used for different kinds of applications. Here are some of the key differences:

1. **Structure and Schema**: 

   - **SQL**: SQL databases are relational and thus have a defined schema. They organize data into tables, rows, and columns, much like a spreadsheet. Each row represents a data record, each column represents a data field, and the schema defines the structure of these tables and the relationships between them. A change in the schema often involves significant modification and downtime.

   - **NoSQL**: NoSQL databases can handle structured, semi-structured, and unstructured data with ease, as they are non-relational. These databases do not require a fixed schema and avoid join operations. This flexibility allows for rapid application change, evolution, and the handling of various data types.

2. **Scalability**:

   - **SQL**: SQL databases typically scale vertically by increasing the horse-power (CPU, RAM, SSD) of the machine. SQL databases use a rigid transaction model that ensures strong consistency.

   - **NoSQL**: NoSQL databases scale horizontally by adding more servers to the database. They distribute the load across numerous servers for large scale data. NoSQL databases use a flexible transaction model that allows for eventual consistency.

3. **ACID vs. BASE**:

   - **SQL**: SQL databases are ACID compliant (Atomicity, Consistency, Isolation, Durability), which ensures that transactions are processed reliably in the event of a failure.

   - **NoSQL**: NoSQL databases follow the BASE model (Basically Available, Soft state, Eventually consistent). The BASE properties ensure availability of the data. The eventual consistency might allow for some inconsistency in the short term in favor of availability, which is a reasonable trade-off in many cases.

4. **Queries and Transactions**:

   - **SQL**: SQL databases use SQL (Structured Query Language) for defining and manipulating the data, which is powerful and versatile. These databases provide a high level of control with a variety of commands.

   - **NoSQL**: NoSQL databases have a dynamic schema for unstructured data, and data is stored in many ways: it can be column-oriented, document-oriented, graph-based, or organized as a KeyValue store. Queries are focused on a collection of documents, often requiring different query language and constructs.

5. **Examples**:

   - **SQL**: MySQL, PostgreSQL, Oracle Database, SQL Server, etc.
   
   - **NoSQL**: MongoDB, Cassandra, HBase, Redis, etc.

The choice between SQL and NoSQL depends entirely on the specific requirements of the project. If transactions require multiple operations, SQL's ACID compliance can be handy. For rapid development, or when data is not structured, NoSQL can be a better choice due to its flexibility.

### Example

An example of SQL (relational database) could be a MySQL database holding a social media website's data, with tables for Users, Posts, Comments, Likes, etc., all related through primary and foreign keys. A NoSQL example could be a MongoDB database holding a blog's data, with documents for each blog post, containing nested comments and author information.

## **Normalization**

This is a database design technique used to reduce data redundancy and avoid undesirable characteristics like Insertion, Update, and Deletion Anomalies. Normal forms, as they are levels of normalization, include First Normal Form (1NF), Second Normal Form (2NF), Third Normal Form (3NF), Boyce & Codd Normal Form (BCNF), Fourth Normal Form (4NF), and Fifth Normal Form (5NF).

Normalization is a method used in databases to reduce data redundancy and avoid data anomalies like insert, update, and delete anomalies. It organizes data into tables and sets up relationships between these tables, leading to efficient data storage.

Normalization involves dividing a database into two or more tables and defining relationships between the tables. The main aim of normalization is to add, delete, and modify data without causing data inconsistencies.

There are several stages of normalization, also known as normal forms, each with a higher level of normalization:

1. **First Normal Form (1NF)**: A table is in 1NF if it contains atomic (indivisible) values for every attribute (column), every attribute value is of the same kind, every row is unique, and the order in which data is stored does not matter.

2. **Second Normal Form (2NF)**: A table is in 2NF if it is in 1NF and every non-primary attribute is fully functionally dependent on the primary key. In other words, if a column is a non-key column, it should be a fact about the whole key, not just part of the key.

3. **Third Normal Form (3NF)**: A table is in 3NF if it is in 2NF and there is no transitive functional dependency. To put it simply, each non-primary attribute must not depend on any other non-primary attribute. 

4. **Boyce-Codd Normal Form (BCNF)**: This is a higher version of 3NF. A table is in BCNF if it is in 3NF and for every non-trivial functional dependency X â†’ Y, X should be a super key. A trivial functional dependency is when Y subset of X.

5. **Fourth Normal Form (4NF)**: A table is in 4NF if it is in BCNF and it has no multi-valued dependencies. 

6. **Fifth Normal Form (5NF)**: A table is in 5NF, also known as Project-Join Normal Form (PJNF), if it is in 4NF and every join dependency in the table is a consequence of its candidate keys.

While normalization makes databases more efficient to maintain, it can also make them more complex because data is distributed across more tables. Whether to normalize a database, and how far to take the process, is often dependent on the specific use case at hand.

### Example

Suppose we have a Sales table in which each row contains the customer name, product purchased, date of purchase, and the salesperson's name who managed the sale. If the salesperson's data (like email, phone number, and office location) is also included in every row, there's a lot of data duplication. By normalizing the data, we'd create a separate Salesperson table, and in the Sales table, we would replace the salesperson's data with a salesperson ID, which is a foreign key linking to the Salesperson table.

## **Indexes**

In a database, an index is a data structure that improves data retrieval speed. Just like an index in a book, it allows the database to find the data without having to scan every row. Creating an index involves the `CREATE INDEX` SQL statement.

An index in a database is a data structure that improves the speed of data retrieval operations. Indexes are used to quickly locate data without having to search every row in a database table each time a database table is accessed. They can be compared to an index in a book, which helps you to quickly locate information without having to flip through every page.

Here are some key points about indexing:

1. **Structure**: An index consists of column values from one table, and those values are stored in a data structure. Common data structures for indexes include B-trees and hash tables.

2. **Creation**: Indexes are created using SQL commands. In most databases, the command is as simple as `CREATE INDEX index_name ON table_name (column_name)`. 

3. **Types of Indexes**: There are several types of indexes, including:

   - **Primary Index**: An index on a set of fields that includes the unique primary key for the field.

   - **Secondary Index**: An index that is not a primary index and can be applied to both key and nonkey columns.

   - **Unique Index**: Ensures data uniqueness in the indexed column.

   - **Composite Index**: An index on two or more columns of a table.

4. **Performance**: Indexes can greatly increase the performance of data retrieval, but they come with a cost. Indexes consume storage space, and will also slow down the speed of writing operations (INSERT, UPDATE, DELETE) because the index also needs to be updated. Therefore, it's a trade-off that needs to be considered based on the specific use case.

5. **Indexing Strategy**: Not every table in a database needs to be indexed. Indexing can be most beneficial on larger tables that have frequently queried columns. Also, columns that have a high degree of uniqueness, such as IDs, are often good candidates for indexing.

In general, the goal of indexing is to speed up retrieval operations on a database. It's a common technique for optimizing database performance and is an essential part of database design and management.

### Example

Let's say we frequently query a Users table based on a username field. By creating an index on username, the database can find the associated data more quickly, similar to how an index in a book helps you find information without reading the entire book.

## **Transactions**

In a database, a transaction is a single unit of work. Ideally, a database transaction satisfies the ACID properties:
   
   - Atomicity: The whole transaction is processed or nothing is processed.
   
   - Consistency: A transaction brings the database from one valid state to another.
   
   - Isolation: The execution of one transaction is isolated from other transactions.
   
   - Durability: Once a transaction has been committed, it remains so.

A transaction in a database is a single unit of logical work, composed of one or more SQL statements. Transactions are a fundamental component of database systems.

Transactions in a database environment have two main purposes:

1. To provide reliable units of work that allow correct recovery from failures and keep a database consistent even in cases of system failure, when execution stops (completely or partially) and many operations upon a database remain uncompleted, with unclear status.

2. To provide isolation between programs accessing a database concurrently. If this isolation is not provided, the program's outcome is possibly erroneous.

The acronym ACID stands for Atomicity, Consistency, Isolation, Durability. These are properties of a reliable transaction processing system:

1. **Atomicity**: This property ensures that a transaction is treated as a single, indivisible unit, which either succeeds completely, or fails completely. If any part of the transaction fails, the entire transaction fails, and the database state is left unchanged.

2. **Consistency**: This property ensures that a transaction brings the database from one valid state to another. Consistency is ensured through the use of database constraints.

3. **Isolation**: This property ensures that the concurrent execution of transactions leaves the database in the same state that would have been obtained if the transactions were executed sequentially.

4. **Durability**: This property ensures that once a transaction has been committed, it will remain so, even in the event of power loss, crashes, or errors.

To manage transactions, the following commands are used:

- `BEGIN TRANSACTION` - to start a transaction.
- `COMMIT` - to save the work done.
- `ROLLBACK` - to undo the changes that have not already been saved to the database.
- `SAVEPOINT` - creates points within the groups of transactions in which to ROLLBACK.

A key part of transaction management is dealing with potential conflicts between two transactions, which is typically handled with different levels of transaction isolation. These range from `Read Uncommitted`, the lowest level, which allows dirty reads, up to `Serializable`, the highest level, which provides complete isolation between transactions.

### Example

Consider an example of a bank transfer from account A to account B. This operation involves two steps: subtracting the amount from A and adding it to B. These steps together form a transaction. It's crucial that either both steps complete or neither do. We don't want to be in a situation where the amount is subtracted from A but not added to B, or vice versa.

## **Sharding**

Database sharding is a type of partitioning where data is split across multiple databases, each called a shard. Each shard holds a subset of data and acts as the single source for this subset. Sharding can be complex but it's useful for very large databases as it can help to reduce query response and load times.

Sharding is a type of database partitioning that separates very large databases into smaller, faster, more easily managed parts called data shards. The word "shard" means a small part of a whole. So, each shard is a small part of a larger database that is distributed across multiple servers.

Here are the key points to know about sharding:

1. **Why Sharding?** 

   As your data grows larger and larger, there comes a point when you may need to partition or distribute it across multiple machines for better performance, fault isolation, and data locality. Sharding allows you to hold more data, handle more queries, and process more transactions as you can distribute the load across multiple servers.

2. **How Does Sharding Work?** 

   Sharding involves breaking up your database into smaller databases, each holding a portion of the data. There are different ways to choose how to distribute this data:

   - **Range Sharding**: Data is partitioned according to a range. For example, users with IDs 1 to 10000 might be stored on one shard, while users with IDs 10001 to 20000 would be stored in another.
   
   - **Hash Sharding**: A hash function is used to distribute the data evenly across the shards. This is beneficial because it avoids hotspotsâ€”locations with high activity.
   
   - **List Sharding**: Each shard is assigned a list of values. When a row of data has a column value that matches one of the list values, it gets stored in the corresponding shard.
   
   - **Directory Based Sharding**: In this sharding method, a lookup service is maintained which knows the current location of all the data. Whenever a new data item needs to be inserted or existing data needs to be read/updated, the lookup service is queried to find the appropriate shard.

3. **Challenges of Sharding**: 

   Sharding comes with several complexities, including re-balancing shards (redistributing data), maintaining the necessary infrastructure, complex SQL queries, backup, and data consistency issues. It's also more complex to manage a distributed system than a single database.

4. **When to use Sharding?**

   Sharding should be considered when a single database instance cannot accommodate the write or read throughput, or the size of the database is exceeding the storage capacity of a single DB instance.

Overall, sharding is a complex process and should be implemented carefully. It's a powerful technique for databases that need to scale beyond the capabilities of existing systems, but it should be used with caution because of its complexity.

### Example

If we have a large Users table, we could shard it by user ID, such that users with IDs from 1 to 1,000,000 are on one shard, users with IDs from 1,000,001 to 2,000,000 are on a second shard, and so on.

## **Replication**

Replication is the process of copying data from a database on one server to a database on another server so that all users share the same sort of data. This improves reliability, fault-tolerance, and accessibility. Replication can be done in three ways: snapshot replication, transactional replication, and merge replication.

Database replication is the process of copying data from a database on one server to a database on another server so as to ensure that all the users share the same sort of data. This technique allows for better accessibility and availability of the data, improves performance, and protects the database from data loss.

Here are some key points to know about replication:

1. **Why Replication?** 

   Replication helps to improve the performance and protect the availability of applications because it allows for failover, recovery, load balancing, and distributing data closer to users.

2. **How Does Replication Work?** 

   There are different replication strategies, each serving different purposes:

   - **Snapshot Replication**: The entire database is copied from the master database to the replica at scheduled intervals. This method is best used when the data in the master database doesn't change frequently.

   - **Transactional Replication**: In this method, an initial snapshot of data is applied, and whenever any changes are made in the master database, the individual transactions are captured and propagated to the replicas. This method is best used when you need high availability and a near real-time replica.

   - **Merge Replication**: Data from two or more databases is combined into a single database. It is bidirectional, meaning data can be updated on both master and replica databases and then synchronized.

3. **Master-Slave and Master-Master Replication**: 

   - **Master-Slave Replication**: One database server (the master) responds to all write operations, and one or more other servers (the slaves) handle all read operations. Changes made to the data on the master server are automatically replicated on the slave servers.

   - **Master-Master Replication**: Any changes can be submitted to any database server, and the changes are then propagated to other servers. If conflicts occur (such as two changes affecting the same item), there are conflict resolution processes.

4. **Challenges of Replication**: 

   Replication comes with a set of challenges such as maintaining consistency, dealing with network partitions, handling conflicts (especially in master-master replication), and increased complexity of management.

Overall, replication is a powerful feature for improving the reliability, speed, and availability of databases, but it must be managed with care to prevent data inconsistency and conflicts.

### Example

In a blogging platform, all the write operations (like creating and updating blog posts) could be performed on a master database, and multiple replicas could serve read operations, like users viewing blog posts. This setup helps balance the load and provides redundancy in case the master database fails.

## **Caching**

Caching is a process that stores copies of data in caches. These caches store data that is requested frequently so that it can be accessed quickly. The data in a cache is stored temporarily and duplicates original values stored elsewhere or computed earlier.

Caching is a process that stores copies of data in high-speed storage systems located closer to the application. The fundamental goal of a cache is to speed up data retrieval by storing a copy of data that is expensive or slow to fetch from the main storage layer. 

Here are the key points to know about caching in database systems:

1. **Why Caching?**

    The primary reason to use caching is to increase the speed of data retrieval. Itâ€™s much faster to get data from cache memory than to get data from primary storage. Caching can also reduce the cost, as it can reduce the number of reads and writes to the primary storage.

2. **Types of Caching:**

    - **Database Query Result Cache**: The results of a query are stored in a cache. When the same query is executed again, the DBMS checks the cache to see if the result is already available. If so, it retrieves the result from the cache instead of executing the query against the database again.

    - **Object Cache**: This involves caching entire objects, which might have been created as a result of certain database queries or computations. This is commonly used in object-oriented databases or applications using an Object-Relational Mapping (ORM) tool.

    - **CDN Caching**: This type of caching is used for web applications and involves caching data at the Content Delivery Network (CDN) nodes spread across the world, thus bringing data closer to users and reducing latency.

3. **Cache Replacement Policies:**

    Since cache memory is limited, there must be a policy in place to decide what data to remove from the cache when it is full and new data needs to be added. Common policies include Least Recently Used (LRU), Most Recently Used (MRU), Least Frequently Used (LFU), and First In, First Out (FIFO).

4. **Cache Invalidation:**

    One of the challenges of caching is ensuring that the cache is consistent with the underlying database. When data is updated, it is essential to either update or invalidate the corresponding cache entries to avoid serving stale data.

5. **Caching Technologies:**

    There are various technologies available for caching, such as Memcached, Redis, Ehcache, and many others. Each has its strengths and trade-offs and can be used in different scenarios.

Remember, while caching can significantly improve performance, it also introduces complexity into your system, especially regarding data consistency. Therefore, it's essential to carefully consider your needs and trade-offs when designing a caching strategy.

### Example

If we have a heavily accessed Posts table in a blogging website, we could cache the most recently or frequently accessed posts. When a user requests a cached post, the system retrieves the cached data instead of querying the database.

## **Object-relational Mapping (ORM)**

ORM is a programming technique for converting data between incompatible type systems using object-oriented programming languages. It creates a virtual object database that can be used within the programming language. There are several Python libraries that implement ORM, including SQLAlchemy and the Django ORM.

Object-Relational Mapping (ORM) is a programming technique used to manage the relationship and mapping between object-oriented programming languages and relational databases. In other words, it's a way to interact with your database, like you would with SQL. In fact, an ORM translates all your actions into SQL queries under the hood.

Here are some key points to know about ORM:

1. **Why ORM?** 

   The main advantage of ORM is that it allows developers to interact with the database using the object-oriented paradigm they're comfortable with. It abstracts the underlying SQL, allowing developers to focus on writing code in the language they're using rather than switching back and forth between their language and SQL.

2. **Mapping**

   An ORM system does the mapping from objects to database rows. For instance, in Python, each class corresponds to a table in the database, and each instance of a class corresponds to a row in the table.

3. **CRUD Operations**

   The ORM allows developers to perform create, read, update, and delete (CRUD) operations on the database using object-oriented techniques. For example, saving an object is as easy as calling a method on the object, without having to write an INSERT SQL statement.

4. **Querying**

   ORM provides an API for querying the database, which translates the method calls into SQL queries. This protects developers from the intricacies of SQL and provides a more comfortable interface for querying.

5. **Pros and Cons**

   ORM's main benefit is its simplicity and the ability to shield developers from the complexities of SQL. It promotes more rapid development and maintainability of the codebase. However, ORMs can lead to inefficiency if not used correctly, because the ORM may not generate the most efficient SQL. For complex queries or performance-critical applications, developers may need to write raw SQL for optimization purposes. Furthermore, an ORM can make the application more tightly coupled to a particular type of database.

Examples of ORMs include SQLAlchemy for Python, Hibernate for Java, and ActiveRecord for Ruby. Each of these ORMs provides an abstraction over the database and simplifies database operations. However, understanding the underlying SQL and the database is still crucial for troubleshooting and performance optimization.

### Example

Using Django's ORM in Python, instead of writing a SQL query like SELECT * FROM Users WHERE username='john';, you can write User.objects.get(username='john'). The ORM converts this Python code into SQL under the hood, and you can work with john as a Python object.

Sure! Here are some examples of interacting with databases, normalization, indexing, transactions, and storage design using Python and Django:

**1. SQL (Using SQLite)**
```python
import sqlite3
conn = sqlite3.connect('example.db')

c = conn.cursor()

# Create table
c.execute('''CREATE TABLE stocks
             (date text, trans text, symbol text, qty real, price real)''')

# Insert a row of data
c.execute("INSERT INTO stocks VALUES ('2006-01-05','BUY','RHAT',100,35.14)")

# Save (commit) the changes
conn.commit()

# We can also close the connection if we are done with it.
# Just be sure any changes have been committed or they will be lost.
conn.close()
```

**2. NoSQL (Using MongoDB with PyMongo)**
```python
from pymongo import MongoClient

client = MongoClient()

db = client['test-database']

# Create a document
post = {"author": "Mike", "text": "My first blog post!"}

# Insert a document
posts = db.posts
post_id = posts.insert_one(post).inserted_id

# Querying for documents
posts.find_one({"author": "Mike"})
```

**3. Normalization**
Normalization involves designing your database schema to minimize redundancy and improve data integrity. Here's an example:

Before normalization:
```
Orders
------
OrderID
CustomerID
CustomerName
CustomerAddress
ProductID
ProductName
ProductPrice
Quantity
```

After normalization:
```
Customers       Products            Orders             OrderDetails
---------       --------            ------             ------------
CustomerID      ProductID           OrderID            OrderID
CustomerName    ProductName         CustomerID         ProductID
CustomerAddress ProductPrice        OrderDate          Quantity
```

**4. Indexes**
Indexes speed up querying but slow down writes. Here's an example of creating an index in SQLite:

```python
c.execute("CREATE INDEX idx_symbol ON stocks (symbol)")
```

**5. Transactions**
Transactions ensure that a group of database operations are atomic (i.e., either all succeed or all fail). Here's an example in SQLite:

```python
# Start a transaction
c.execute('BEGIN TRANSACTION')

try:
    c.execute("INSERT INTO stocks VALUES ('2006-01-05','BUY','RHAT',100,35.14)")
    c.execute("INSERT INTO stocks VALUES ('2006-01-05','BUY','GOOG',100,350.14)")
    
    # Commit the transaction if all commands were successful
    conn.commit()
except:
    # Rollback the transaction if any commands failed
    conn.rollback()
```

**6. Storage Design**
Storage design involves determining how your data will be stored and accessed. For example, should you use a relational database or a NoSQL database? Should you use cloud storage or local storage? These decisions depend on your specific use case.

Django ORM (Object-Relational Mapping) makes it easy to interact with your database, like fetching objects from database, saving, updating and deleting.
```python
# Suppose you have a Django model named Book in your application
from myapp.models import Book

# Fetch all books
all_books = Book.objects.all()

# Create a new book
new_book = Book(title='New Book', author='John Doe', price='25.99')
new_book.save()

# Update a book
book_to_update = Book.objects.get(id=1) # fetch the book to update
book_to_update.price = '19.99'
book_to_update.save()

# Delete a book
book_to_delete = Book.objects.get(id=2) # fetch the book to delete
book_to_delete.delete

()
```

These are some very basic examples to give you a brief overview of how to interact with databases using Python and Django. In actual development process, there are a lot more considerations for database and storage design, transaction handling, using indexes and normalization.

In the world of databases, sharding, replication, and caching are advanced topics that are more often than not implemented at the database level and not within the application itself. This is because these techniques involve how data is distributed and managed across multiple machines or servers, which is typically a concern of the database rather than the application that's using the database. However, the application can determine how it interacts with these concepts. Here are brief overviews of these concepts:

**1. Sharding:**
Sharding is a database technique where data is partitioned into smaller, more manageable pieces called 'shards'. Each shard is held on a separate database server instance to spread the load and to overcome the limitations of having a single server. For instance, the MongoDB driver for Python supports sharding at the database level and you can interact with a sharded cluster in the same way you interact with a non-sharded MongoDB database.

**2. Replication:**
Database replication is the frequent electronic copying data from a database in one computer or server to a database in another so that all users share the same level of information. This can be done in various ways like snapshot replication, merge replication, and transactional replication. Replication is a complex task often done at the database level and most popular databases support replication out of the box, including MySQL, PostgreSQL, MongoDB, etc.

**3. Caching:**
Caching can drastically speed up your application by storing frequently accessed data in a faster storage system. Here's a simple example of how you might use caching in Python with Redis:

```python
import redis

# Create a redis client
r = redis.Redis(host='localhost', port=6379, db=0)

def get_data(id):
    # Try to get the result from the cache
    data = r.get(id)
    
    if data is None:
        # If the data isn't in the cache, get it from the database
        data = get_data_from_database(id)
        
        # Store the result in the cache for 1 hour
        r.setex(id, 3600, data)

    return data
```

In this example, `get_data` first tries to get the requested data from the Redis cache. If the data is not in the cache, it fetches the data from the database, then stores the result in the cache for 1 hour.

Please note, these topics are extensive and cannot be fully explained or exemplified in a few lines of code. It is suggested to dive deeper into each topic with comprehensive resources and documentation.